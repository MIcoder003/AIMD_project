{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Deploy the model Endpoint"
      ],
      "metadata": {
        "id": "CTnd6VqeS3iR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPiEs0_uS0Yg"
      },
      "outputs": [],
      "source": [
        "import sagemaker\n",
        "from sagemaker.sklearn.model import SKLearnModel\n",
        "from sagemaker import get_execution_role\n",
        "\n",
        "# 1. Setup\n",
        "sagemaker_session = sagemaker.Session()\n",
        "role = get_execution_role()\n",
        "\n",
        "# S3 location of your packaged model tarball\n",
        "\n",
        "model_data_s3_path = 's3://ecomrecdata/model_artifacts/model.tar.gz'\n",
        "\n",
        "# The version of the Scikit-learn container to use\n",
        "# Check AWS documentation for the latest versions\n",
        "framework_version = '1.2-1'\n",
        "py_version = 'py3'\n",
        "\n",
        "# 2. Create a SageMaker Model\n",
        "\n",
        "model = SKLearnModel(\n",
        "    model_data=model_data_s3_path,\n",
        "    role=role,\n",
        "    entry_point='inference.py',\n",
        "    framework_version=framework_version,\n",
        "    py_version=py_version,\n",
        "    sagemaker_session=sagemaker_session\n",
        ")\n",
        "\n",
        "# 3. Deploy the Model to a Real-time Endpoint\n",
        "predictor = model.deploy(\n",
        "    initial_instance_count=1,\n",
        "    instance_type='ml.t2.medium',\n",
        "    endpoint_name='hybrid-recommender-endpoint'\n",
        ")\n",
        "\n",
        "print(f\"Deployment complete. Endpoint Name: {predictor.endpoint_name}\")\n",
        "\n",
        "# 4. Example Inference Call\n",
        "test_payload = {\n",
        "    \"user_id\": 483717,\n",
        "    \"alpha\": 0.7,\n",
        "    \"top_n\": 5\n",
        "}\n",
        "\n",
        "# The predictor will automatically call input_fn, predict_fn, and output_fn\n",
        "response = predictor.predict(test_payload, initial_args={'ContentType': 'application/json', 'Accept': 'application/json'})\n",
        "\n",
        "print(\"\\n--- Inference Response ---\")\n",
        "print(response)\n",
        "\n",
        "# 5. Clean up (Important to avoid unnecessary charges)\n",
        "predictor.delete_endpoint()"
      ]
    }
  ]
}