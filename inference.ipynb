{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "import json\n",
        "import logging\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "60FzW67vUk-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(level=logging.INFO)"
      ],
      "metadata": {
        "id": "H4omNacuUpLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global variables for the loaded model and auxiliary data\n",
        "model = None\n",
        "user_inv_map = None\n",
        "item_map = None\n",
        "train_sparse = None\n",
        "train_data = None\n",
        "itemid_to_index = None\n",
        "item_ids = None\n",
        "tfidf_matrix = None"
      ],
      "metadata": {
        "id": "dhxLhDi8Uplu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_recommendations(user_id, alpha=0.5, top_n=10):\n",
        "    \"\"\"\n",
        "    Generates hybrid (ALS and Content-Based) recommendations for a user.\n",
        "    \"\"\"\n",
        "    global model, user_inv_map, item_map, train_sparse, train_data, itemid_to_index, item_ids, tfidf_matrix\n",
        "\n",
        "    # Check for all required dependencies\n",
        "    if any(x is None for x in [model, user_inv_map, item_map, train_sparse, train_data, itemid_to_index, item_ids, tfidf_matrix]):\n",
        "        logging.error(\"Inference dependencies not loaded. Cannot proceed.\")\n",
        "        return []\n",
        "\n",
        "    if user_id not in user_inv_map:\n",
        "        logging.debug(f\"User {user_id} not in training data\")\n",
        "        return []\n",
        "\n",
        "    user_index = user_inv_map[user_id]\n",
        "\n",
        "    # 1. ALS scores (Collaborative Filtering)\n",
        "    try:\n",
        "        user_row = train_sparse[user_index]\n",
        "        # model.recommend is assumed to be from the 'lightfm' or similar library\n",
        "        als_recs = model.recommend(\n",
        "            user_index,\n",
        "            user_row,\n",
        "            N=top_n * 2,\n",
        "            filter_already_liked_items=True\n",
        "        )\n",
        "        item_indices_als, scores = als_recs\n",
        "        # Map item indices back to original item IDs\n",
        "        als_scores = {item_map.get(iid): score for iid, score in zip(item_indices_als, scores) if item_map.get(iid) is not None}\n",
        "    except IndexError as e:\n",
        "        logging.error(f\"IndexError in ALS for user {user_id}: {e}\")\n",
        "        return []\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error in ALS recommendation for user {user_id}: {e}\")\n",
        "        return []\n",
        "\n",
        "    # 2. Content-based scores\n",
        "    user_interactions = train_data[train_data['visitorid'] == user_id]['itemid'].values\n",
        "    item_indices_cb = [itemid_to_index.get(iid) for iid in user_interactions if itemid_to_index.get(iid) is not None]\n",
        "\n",
        "    if not item_indices_cb:\n",
        "        logging.debug(f\"No valid item interactions for user {user_id}. Returning pure ALS.\")\n",
        "        return list(als_scores.keys())[:top_n]\n",
        "\n",
        "    # Vectorized content-based scoring\n",
        "    # Calculate the average TF-IDF vector of the items the user interacted with\n",
        "    user_tfidf = np.asarray(tfidf_matrix[item_indices_cb].mean(axis=0))\n",
        "\n",
        "    # Calculate cosine similarity between the user's average TF-IDF and all item TF-IDF vectors\n",
        "    sims = cosine_similarity(user_tfidf.reshape(1, -1), tfidf_matrix).flatten()\n",
        "\n",
        "    if len(sims) != len(item_ids):\n",
        "        logging.error(f\"Mismatch: sims length {len(sims)} != item_ids length {len(item_ids)}\")\n",
        "        return list(als_scores.keys())[:top_n]\n",
        "\n",
        "    cb_scores = {}\n",
        "    for idx, score in enumerate(sims):\n",
        "        item_id = item_ids[idx] # item_ids maps index back to original item ID\n",
        "        cb_scores[item_id] = score\n",
        "\n",
        "    # 3. Combine scores\n",
        "    all_items = set(als_scores.keys()) | set(cb_scores.keys())\n",
        "    combined_scores = {}\n",
        "    for item in all_items:\n",
        "        # Get scores, defaulting to 0 if an item only appears in one set\n",
        "        als_score = als_scores.get(item, 0)\n",
        "        cb_score = cb_scores.get(item, 0)\n",
        "        # Apply the blending formula\n",
        "        combined_scores[item] = alpha * als_score + (1 - alpha) * cb_score\n",
        "\n",
        "    # 4. Rank and return top N\n",
        "    ranked_items = sorted(combined_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [item for item, _ in ranked_items[:top_n]]"
      ],
      "metadata": {
        "id": "cRfpWXobUr2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_fn(model_dir):\n",
        "    \"\"\"\n",
        "    Load the model and auxiliary files from the model directory.\n",
        "\n",
        "    This function is called once when the container starts.\n",
        "    The 'model_dir' is the path where your model artifacts from S3\n",
        "    are downloaded (the 'code' directory in your compressed tarball).\n",
        "    \"\"\"\n",
        "    global model, user_inv_map, item_map, train_sparse, train_data, itemid_to_index, item_ids, tfidf_matrix\n",
        "\n",
        "    # 1. Load the ALS model artifact\n",
        "    # Assuming the joblib file is named 'als_model.joblib' and is in the tarball\n",
        "    try:\n",
        "        model_path = os.path.join(model_dir, 'als_model.joblib')\n",
        "        model = joblib.load(model_path)\n",
        "        logging.info(f\"Successfully loaded ALS model from {model_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading als_model.joblib: {e}\")\n",
        "        raise e\n",
        "\n",
        "    # 2. Load Auxiliary Data\n",
        "    # For a complex hybrid model, you MUST include all auxiliary data\n",
        "    # (mappings, matrices, training data frame, etc.) in your model tarball.\n",
        "    # I'm assuming they are saved as joblib or numpy files.\n",
        "    try:\n",
        "        # Example loading of auxiliary files - adjust file names as necessary!\n",
        "        user_inv_map = joblib.load(os.path.join(model_dir, 'user_inv_map.joblib'))\n",
        "        item_map = joblib.load(os.path.join(model_dir, 'item_map.joblib'))\n",
        "        train_sparse = joblib.load(os.path.join(model_dir, 'train_sparse.joblib')) # Must be a scipy sparse matrix\n",
        "        train_data = pd.read_csv(os.path.join(model_dir, 'train_data.csv')) # Assuming train_data is a CSV\n",
        "        itemid_to_index = joblib.load(os.path.join(model_dir, 'itemid_to_index.joblib'))\n",
        "        item_ids = joblib.load(os.path.join(model_dir, 'item_ids.joblib')) # A list/array of item IDs\n",
        "        tfidf_matrix = joblib.load(os.path.join(model_dir, 'tfidf_matrix.joblib')) # Must be a scipy sparse or dense matrix\n",
        "\n",
        "        logging.info(\"Successfully loaded all auxiliary data for hybrid model.\")\n",
        "\n",
        "        # Ensure sparse matrices are in a usable format\n",
        "        if isinstance(train_sparse, np.ndarray):\n",
        "            train_sparse = csr_matrix(train_sparse)\n",
        "        if isinstance(tfidf_matrix, np.ndarray):\n",
        "            tfidf_matrix = csr_matrix(tfidf_matrix)\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error loading auxiliary files. Check the file names in your tarball: {e}\")\n",
        "        # The inference will fail if these are missing, which is correct behavior\n",
        "        raise e\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "C5sZgMoSU0q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def input_fn(request_body, request_content_type):\n",
        "    \"\"\"\n",
        "    Parses the request body into a user ID for prediction.\n",
        "    \"\"\"\n",
        "    if request_content_type == 'application/json':\n",
        "        data = json.loads(request_body)\n",
        "        # Expecting a structure like: {\"user_id\": \"visitor_123\", \"alpha\": 0.6, \"top_n\": 5}\n",
        "        # We primarily need the user_id. Default alpha and top_n are used otherwise.\n",
        "        user_id = data.get('user_id')\n",
        "        alpha = data.get('alpha', 0.5)\n",
        "        top_n = data.get('top_n', 10)\n",
        "        return user_id, alpha, top_n\n",
        "\n",
        "    raise ValueError(f\"Unsupported content type: {request_content_type}\")"
      ],
      "metadata": {
        "id": "t6LKHNGVU-UD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_fn(input_data, model):\n",
        "    \"\"\"\n",
        "    Runs the recommendation logic.\n",
        "    \"\"\"\n",
        "    user_id, alpha, top_n = input_data\n",
        "    logging.info(f\"Generating recommendations for user {user_id} with alpha={alpha}, top_n={top_n}\")\n",
        "\n",
        "    # The 'model' argument here is the return value of model_fn,\n",
        "    # but since our actual logic relies on global variables for auxiliary data,\n",
        "    # we call our custom function directly.\n",
        "    recommendations = hybrid_recommendations(user_id, alpha, top_n)\n",
        "    return recommendations"
      ],
      "metadata": {
        "id": "GsCp1Nw8VEc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def output_fn(prediction, accept):\n",
        "    \"\"\"\n",
        "    Formats the prediction result into a response body.\n",
        "    \"\"\"\n",
        "    if accept == 'application/json':\n",
        "        response_body = json.dumps({'recommendations': prediction})\n",
        "        return response_body, accept\n",
        "\n",
        "    # Handle other acceptable response formats\n",
        "    raise ValueError(f\"Unsupported accept type: {accept}\")"
      ],
      "metadata": {
        "id": "feRqJrpIVGVZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}